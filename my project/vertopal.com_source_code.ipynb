{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np import pandas as pd import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data=pd.readcsv(’framingham.csv’)\n",
    "\n",
    "data.head()\n",
    "\n",
    "data.drop(‘education’,axis=1,inplace=True)\n",
    "\n",
    "data.head()\n",
    "\n",
    "drop=\\[‘currentsmoker’,diaBP’\\]\n",
    "\n",
    "data.drop(drop,axis=1,inplace=True)\n",
    "\n",
    "#data.head()\n",
    "\n",
    "data.shape\n",
    "\n",
    "print(‘number of outliers to be removed\n",
    "is’,len(data\\[data\\[‘BMI’\\]\\>43\\])+len(data\\[data\\[‘glucose’\\]\\>350\\])+len(data\\[data\\[‘totChol’\\]\\>450\\])+len(data\\[data\\[‘svsBP’\\]\\>220\\])\n",
    "\n",
    "data=data\\[\\`(data\\[‘totChol’\\]\\>450)\\]\n",
    "\n",
    "data=data\\[\\`(data\\[‘svsBP’\\]\\>220)\\]\n",
    "\n",
    "data=data\\[\\`(data\\[‘BMI’\\]\\>43)\\]\n",
    "\n",
    "data=data\\[\\`(data\\[‘glucose’\\]\\>350)\\]\n",
    "\n",
    "data.shape\n",
    "\n",
    "data.isnull().sum()\n",
    "\n",
    "data=data.dropna(axis=0,inplace=False)\n",
    "\n",
    "data.isnull().sum()\n",
    "\n",
    "data.shape\n",
    "\n",
    "from sklearn.model selection import train test split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y=data\\[“TenYearCHD”\\]\n",
    "\n",
    "X=data.drop(‘TenYearCHD’,axis=1)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=0)\n",
    "\n",
    "scaler = StandardScaler( )\n",
    "\n",
    "X_train = scaler.fittransform(X_train)\n",
    "\n",
    "X_test =scaler.transform(X_test)\n",
    "\n",
    "from sklearn . svm\n",
    "\n",
    "import SVC\n",
    "\n",
    "from sklearn.metrics\n",
    "\n",
    "import confusion_matrix , accuracy_score , roc_curve ,\n",
    "classificationreport\n",
    "\n",
    "svc = SVC( kernel = ’rbf’,C=2)\n",
    "\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "svc_predicted = svc . predict(X_test)\n",
    "\n",
    "svc_conf_matrix = confusion_matrix ( y_test , svc_predicted)\n",
    "\n",
    "svc_acc_score = accuracy_score ( y_test , svc_predicted)\n",
    "\n",
    "print( ” confussion matrix ” )\n",
    "\n",
    "print ( svc_conf_matrix)\n",
    "\n",
    "print(””)\n",
    "\n",
    "print(”Accuracy of Support Vector Classifier:”,svc_acc_score\\*100,’’)\n",
    "\n",
    "print(classification_report(y_test,svc_predicted))\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt=DecisionTreeClassifier(criterion=’entropy’,random_state=0,max_depth=6)\n",
    "\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "dt_predicted=dt.predict(X_test)\n",
    "\n",
    "dt_conf_matrix=confusion_matrix(y_test,dt_predicted)\n",
    "\n",
    "dt_acc_score=accuracy_score(y_test,dt_predicted)\n",
    "\n",
    "print(”confussion_matrix”)\n",
    "\n",
    "print(dt_conf_matrix)\n",
    "\n",
    "print(””)\n",
    "\n",
    "print(”Accuracy of DecisionTreeClassifier:”,dt_acc_score\\*100,’’)\n",
    "\n",
    "print(classification_report(y_test,dt_predicted))\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "knn_predicted=knn.predict(X_test)\n",
    "\n",
    "knn_conf_matrix=confusion_matrix(y_test,knn_predicted)\n",
    "\n",
    "knn_acc_score=accuracy_score(y_test,knn_predicted)\n",
    "\n",
    "print(”confussionmatrix”)\n",
    "\n",
    "print(knnconfmatrix)\n",
    "\n",
    "print(””)\n",
    "\n",
    "print(”Accuracy of K−NeighborsClassifier:”,knn_acc_score\\*100,’’)\n",
    "\n",
    "print(classification_report(y_test,knn_predicted))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=20,random_state=2,max_depth=5)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "rf_predicted=rf.predict(X_test)\n",
    "\n",
    "rf_conf_matrix=confusion_matrix(y_test,rf_predicted)\n",
    "\n",
    "rf_acc_score=accuracy_score(y_test,rf_predicted)\n",
    "\n",
    "print(”confussionmatrix”)\n",
    "\n",
    "print(rf_conf_matrix)\n",
    "\n",
    "print(””)\n",
    "\n",
    "print(”Accuracy of RandomForest:”,rf_acc_score\\*100,’’)\n",
    "\n",
    "print(classification_report(y_test,rf_predicted))\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb=XGBClassifier(learningrate=0.01,nestimators=25,maxdepth=15,gamma=0.6,subsample=0.52,colsample_bytree=0.6,seed=27,\n",
    "reg_lambda=2,booster=’dart’,colsample_bylevel=0.6,colsample_bynode=\n",
    "0.5,uselabelencoder=False)\n",
    "\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "xgb_predicted=xgb.predict(X_test)\n",
    "\n",
    "xgb_conf_matrix=confusion_matrix(y_test,xgb_predicted)\n",
    "\n",
    "xgb_acc_score=accuracy_score(y_test,xgb_predicted)\n",
    "\n",
    "print(”confussion_matrix”)\n",
    "\n",
    "print(xgb_conf_matrix)\n",
    "\n",
    "print(””)\n",
    "\n",
    "print(”Accuracy of Extreme Gradient Boost:”,xgb_acc_score\\*100,’’)\n",
    "\n",
    "print(classification_report(y_test,xgb_predicted))\n",
    "\n",
    "from sklearn.ensemble\n",
    "\n",
    "import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(’tuning n_estimators’)\n",
    "\n",
    "params1={’n_estimators’:range(205,210,1)}\n",
    "\n",
    "estimator=GradientBoostingClassifier(learningrate=0.01, maxdepth=15,\n",
    "subsample=0.52)\n",
    "\n",
    "grid_xgb1=GridSearchCV(estimator, params1, cv=5, scoring=’accuracy’,\n",
    "n_jobs=1, verbose=False) grid_result=grid_xgb1.fit(X_train,y_train)\n",
    "\n",
    "print(” Best:%f using %s\n",
    "”%(grid_result.bestscore,grid_result.best_params))\n",
    "\n",
    "means=grid_result.cv_results\\[’mean_test_score’\\]\n",
    "\n",
    "stds=grid_result.cv_results\\[’std_test_score’\\]\n",
    "\n",
    "params=grid_result.cv_results\\[’params’\\]\n",
    "\n",
    "for mean, stdev ,param in zip(means,stds,params):\n",
    "\n",
    "print(”%f(%f)with:%r”%(mean,stdev,param))\n",
    "\n",
    "print(’tuning max_depth and min_sample_split’)\n",
    "\n",
    "params2={’max_depth’:range(5,25,1),’min_samples_split’:range(400,1001,200)}\n",
    "\n",
    "estimator=GradientBoostingClassifier(learningrate=0.1, n_estimators=80,\n",
    "max_features=’sqrt’, subsample=0.8, random_state=10)\n",
    "\n",
    "grid_xgb2=GridSearchCV(estimator, params2, cv=5, scoring=’accuracy’,\n",
    "n_jobs=−1, verbose=True)\n",
    "\n",
    "grid_result=grid_xgb2.fit(X_train,y_train)\n",
    "\n",
    "print(”Best:%f using %s ”\n",
    "%(grid_result.best_score,grid_result.best_params))\n",
    "\n",
    "means=grid_result.cv_results\\[’mean_test_score’\\]\n",
    "\n",
    "stds=grid_result.cv_results\\[’stdtestscore’\\]\n",
    "\n",
    "params=grid_result.cv_results\\[’params’\\]\n",
    "\n",
    "for mean,stdev,param in zip(means,stds,params):\n",
    "\n",
    "print(”%f (%f) with:%r ”%(mean,stdev,param))"
   ],
   "id": "099bc71d-668c-4d5a-bd6b-908d5f1a10bc"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
